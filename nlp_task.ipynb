{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP test task for BST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_tin.csv', encoding='cp1251')\n",
    "df_test = pd.read_csv('test_tin.csv', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.09.19 через сайт в разделе \"Рефинансировани...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Добрый день! Неоднократно поступают звонки по ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В первый раз решила воспользоваться кредитной ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>На самом дело уже накипело из-за участившегося...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Если вы дорожите своими нервами - ни при каких...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  isPositive\n",
       "0  27.09.19 через сайт в разделе \"Рефинансировани...           0\n",
       "1  Добрый день! Неоднократно поступают звонки по ...           0\n",
       "2  В первый раз решила воспользоваться кредитной ...           0\n",
       "3  На самом дело уже накипело из-за участившегося...           0\n",
       "4  Если вы дорожите своими нервами - ни при каких...           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yay, transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a1f0ffc63943558067361b79fe42e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/499 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be79dfff124449b29b031220e7ea2177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a737bbc0eb4082a7b4c30287c2b736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31cdc8d1fe34c1e9c56746d972e395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/943 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9556aca628354c0f868025240060b9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/679M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "\n",
    "# well, transformers, obvioulsy\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    'blanchefort/rubert-base-cased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
    "\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, max_length=512, padding=True,\n",
    "                       truncation=True, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = {0 : 'neutral', 1 : 'positive', 2 : 'negative'}\n",
    "labels = {0 : 'negative', 1 : 'positive'}\n",
    "# сonverting from nums to something nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking accuracy on 'train' subset\n",
    "preds = pd.DataFrame({'label' : [], 'prediction': []})\n",
    "for idx in range(len(df_train)):\n",
    "    pred = predict(df_train['text'].iloc[idx])\n",
    "\n",
    "    pred_label = pred_labels[pred[0]]\n",
    "    actual_label = labels[df_train['isPositive'].iloc[idx]]\n",
    "\n",
    "    preds = preds.append({'label' : actual_label, 'prediction': pred_label}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.replace('neutral', 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.2981220657277"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds['label'] == preds['prediction']) / len(preds) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ight, 98% accuracy, good enought I guess?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions \n",
    "preds_test = pd.DataFrame({'prediction': []})\n",
    "correct = 0\n",
    "for idx in range(len(df_test)):\n",
    "    pred = predict(df_test['text'].iloc[idx])\n",
    "\n",
    "    pred_label = pred_labels[pred[0]]\n",
    "\n",
    "    preds_test = preds_test.append(\n",
    "        {'prediction': pred_label}, ignore_index=True)\n",
    "    if pred_label == actual_label:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      negative\n",
       "1      positive\n",
       "2      positive\n",
       "3      negative\n",
       "4      positive\n",
       "         ...   \n",
       "995    negative\n",
       "996    positive\n",
       "997    negative\n",
       "998     neutral\n",
       "999    negative\n",
       "Name: prediction, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don not agree with the idea of not using 'neutral', but what can I say...\n",
    "#   changing human-readable into nums\n",
    "#   and commiting to the idea 'if its not positive - its negative'\n",
    "preds_test = preds_test.replace('negative', 0)\n",
    "preds_test = preds_test.replace('neutral', 0)\n",
    "preds_test = preds_test.replace('positive', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Добрый день! Я являюсь клиентом Тинькофф банк ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хочу выразить огромную благодарность банку Тин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Выражаю благодарность К-ву Александру В. за ст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В январе 2019 года оформила потребительский кр...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Добрый день. Хочу поблагодарить банк Тинькофф ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Приветствую! 18.02 хотел совершить несколько п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Сотрудник Шахноза (6904552) очень грамотно и б...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Добрый день!Я являюсь клиентом банка, теперь у...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Столкнулись с проблемой: нужно было провести п...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Всем здраствуйте,  хочу оставить еще один отзы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  isPositive\n",
       "0    Добрый день! Я являюсь клиентом Тинькофф банк ...           0\n",
       "1    Хочу выразить огромную благодарность банку Тин...           1\n",
       "2    Выражаю благодарность К-ву Александру В. за ст...           1\n",
       "3    В январе 2019 года оформила потребительский кр...           0\n",
       "4    Добрый день. Хочу поблагодарить банк Тинькофф ...           1\n",
       "..                                                 ...         ...\n",
       "995  Приветствую! 18.02 хотел совершить несколько п...           0\n",
       "996  Сотрудник Шахноза (6904552) очень грамотно и б...           1\n",
       "997  Добрый день!Я являюсь клиентом банка, теперь у...           0\n",
       "998  Столкнулись с проблемой: нужно было провести п...           0\n",
       "999  Всем здраствуйте,  хочу оставить еще один отзы...           0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['isPositive'] = preds_test['prediction']\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('predictions_nlp.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What else could have been used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well  \n",
    "Transformers have been showing SOTA results for some time in NLP *(and CV for that matter...)*, pretrained models are widely availible and are crazilly easy to use. Why whould anyone else use anything other than transformers for this task?  \n",
    "\n",
    "Yeah, I need to show my expertise in this field and thats the whole idea I guess...  \n",
    "Let me just say what could've been done to solve this problem (if today was like 2017):  \n",
    "\n",
    "- `Rule based` aprroach, such as `Bag of words`: assining weight to each words and calculiting the result *(kindergarden way)*\n",
    "- `Basic machine learning models`, such as `Naive Bayes`: we can remove stop words, *vectorize* text, construct `DTM`, use some sort of `dimensionality reduction` algorythm and train the model. *(high scool way)*\n",
    "- `Deep learning`, such as using `LSTM` - turn text into word embeddings and train the model *(pre 2017 'good' way I guess)*\n",
    "- `Pre-trained transformers`, like basic Transformer, BERT (or its variations), ERNIE, etc. It would be a bad idea to train transformer-like model from scratch yourself, so we might want to finetune an already existing one. But do we really need to, if we already have models 98% accuracy? And even if we want to - we'd have to use already existing things (tokenizers). So what's the purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anyway, fine-tuning transformers, an example\n",
    "\n",
    "My colab is in full use 95% of Google allocated to me time, I can't afford such a journey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "   return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "\n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(\n",
    "       predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "repo_name = \"very-good-fine-tuned-model\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    " \n",
    "sentiment_model = pipeline(model=\"empyempt/very-good-fine-tuned-model\")\n",
    "sentiment_model([\"I love this move\", \"This movie sucks!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ye, that's roughly it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20f5b49acdb8aa5482bf611cd625371fff780f4a1ea28b5df1442e16c229ca99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
